{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文件操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File operation begin !\n",
      "File done 24.15 seconds to operation !\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil \n",
    "import random\n",
    "import time\n",
    "print('File operation begin !')\n",
    "t=time.time()\n",
    "TRAIN_PATH = \"./train/\"\n",
    "TEST_PATH = \"./test/\"\n",
    "# SAMPLE_PATH = \"sample/\"\n",
    "CAT_PATH = \"cat/\"\n",
    "DOG_PATH = \"dog/\"\n",
    "CLEAN_TRAIN = \"clean_train/\"\n",
    "\n",
    "def checkDir(dir_path):\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "\n",
    "checkDir(CAT_PATH)\n",
    "checkDir(DOG_PATH)\n",
    "checkDir(CLEAN_TRAIN)\n",
    "\n",
    "train_files = os.listdir(TRAIN_PATH)\n",
    "for file in train_files:\n",
    "    if 'dog' in file:\n",
    "        shutil.copy(TRAIN_PATH + file, DOG_PATH + file)\n",
    "    if 'cat' in file:\n",
    "        shutil.copy(TRAIN_PATH + file, CAT_PATH + file)    \n",
    "t2 = time.time()\n",
    "print('File done', round(t2 - t, 2), 'seconds to operation !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pylab as plb\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Dropout, Dense\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.utils import shuffle\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  数据可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "for file in train_files:\n",
    "    img = cv2.imread(TRAIN_PATH + file)\n",
    "    imgs.append(img.shape[0:2])\n",
    "#     break\n",
    "    \n",
    "imgs = np.array(imgs)\n",
    "x = imgs[:,0]\n",
    "y = imgs[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leezhe/anaconda3/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['random', 'shuffle']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "plt.title('cat-width-height')\n",
    "plt.xlabel('Width')\n",
    "plt.ylabel('Height')\n",
    "plt.scatter(x, y, alpha = 0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自带的预处理方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data1(imgDir, size=224):\n",
    "    imgDir = shuffle(imgDir)\n",
    "    train_x = np.zeros((len(imgDir), size, size, 3), dtype=np.float32)\n",
    "    train_y = np.zeros(len(imgDir), dtype=np.uint8)\n",
    "    for index, file in enumerate(imgDir):        \n",
    "        img = image.load_img(file, target_size=(size, size))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        train_x[index] = preprocess_input(x)    \n",
    "        if 'dog' in file:\n",
    "            train_y[index] = 1\n",
    "    return train_x, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proprecessing begin !\n",
      "1215.41 seconds to preprocessing !\n"
     ]
    }
   ],
   "source": [
    "# cat 0  dog 1\n",
    "print('Proprecessing begin !')\n",
    "t=time.time()\n",
    "train_dir = glob.glob('train_all/*.jpg')\n",
    "train_x, train_y = get_train_data1(train_dir)\n",
    "t2 = time.time()\n",
    "print(round(t2 - t, 2), 'seconds to preprocessing !')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------------------------------------------------------------------------------------------------------\n",
    "### 50% Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "19990/20000 [============================>.] - ETA: 2s - loss: 0.1564 - acc: 0.9376\n",
      "Epoch 00001: val_loss improved from inf to 0.04456, saving model to model_best.h5\n",
      "20000/20000 [==============================] - 5523s 276ms/step - loss: 0.1564 - acc: 0.9375 - val_loss: 0.0446 - val_acc: 0.9854\n",
      "Epoch 2/10\n",
      "19990/20000 [============================>.] - ETA: 2s - loss: 0.0777 - acc: 0.9699\n",
      "Epoch 00002: val_loss improved from 0.04456 to 0.03630, saving model to model_best.h5\n",
      "20000/20000 [==============================] - 5346s 267ms/step - loss: 0.0777 - acc: 0.9699 - val_loss: 0.0363 - val_acc: 0.9872\n",
      "Epoch 3/10\n",
      "19990/20000 [============================>.] - ETA: 2s - loss: 0.0541 - acc: 0.9809\n",
      "Epoch 00003: val_loss improved from 0.03630 to 0.03114, saving model to model_best.h5\n",
      "20000/20000 [==============================] - 5357s 268ms/step - loss: 0.0541 - acc: 0.9809 - val_loss: 0.0311 - val_acc: 0.9892\n",
      "Epoch 4/10\n",
      "19990/20000 [============================>.] - ETA: 2s - loss: 0.0420 - acc: 0.9854\n",
      "Epoch 00004: val_loss improved from 0.03114 to 0.03020, saving model to model_best.h5\n",
      "20000/20000 [==============================] - 5645s 282ms/step - loss: 0.0419 - acc: 0.9854 - val_loss: 0.0302 - val_acc: 0.9900\n",
      "Epoch 5/10\n",
      "19990/20000 [============================>.] - ETA: 2s - loss: 0.0328 - acc: 0.9883\n",
      "Epoch 00005: val_loss improved from 0.03020 to 0.02960, saving model to model_best.h5\n",
      "20000/20000 [==============================] - 5445s 272ms/step - loss: 0.0328 - acc: 0.9883 - val_loss: 0.0296 - val_acc: 0.9900\n",
      "Epoch 6/10\n",
      "19990/20000 [============================>.] - ETA: 2s - loss: 0.0278 - acc: 0.9905\n",
      "Epoch 00006: val_loss did not improve\n",
      "20000/20000 [==============================] - 5308s 265ms/step - loss: 0.0278 - acc: 0.9905 - val_loss: 0.0302 - val_acc: 0.9894\n",
      "Epoch 7/10\n",
      "19990/20000 [============================>.] - ETA: 2s - loss: 0.0199 - acc: 0.9933\n",
      "Epoch 00007: val_loss improved from 0.02960 to 0.02953, saving model to model_best.h5\n",
      "20000/20000 [==============================] - 5321s 266ms/step - loss: 0.0199 - acc: 0.9933 - val_loss: 0.0295 - val_acc: 0.9898\n",
      "Epoch 8/10\n",
      "19990/20000 [============================>.] - ETA: 2s - loss: 0.0167 - acc: 0.9943\n",
      "Epoch 00008: val_loss improved from 0.02953 to 0.02855, saving model to model_best.h5\n",
      "20000/20000 [==============================] - 5297s 265ms/step - loss: 0.0167 - acc: 0.9943 - val_loss: 0.0285 - val_acc: 0.9902\n",
      "Epoch 9/10\n",
      "19990/20000 [============================>.] - ETA: 2s - loss: 0.0159 - acc: 0.9947\n",
      "Epoch 00009: val_loss did not improve\n",
      "20000/20000 [==============================] - 5276s 264ms/step - loss: 0.0159 - acc: 0.9947 - val_loss: 0.0290 - val_acc: 0.9894\n",
      "Epoch 10/10\n",
      "19990/20000 [============================>.] - ETA: 2s - loss: 0.0128 - acc: 0.9963\n",
      "Epoch 00010: val_loss did not improve\n",
      "20000/20000 [==============================] - 5289s 264ms/step - loss: 0.0128 - acc: 0.9963 - val_loss: 0.0286 - val_acc: 0.9898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a27e3584a8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "opt = SGD(lr=0.0001, momentum=0.9)\n",
    "myinput = Input(shape=(224, 224, 3))\n",
    "base_model = ResNet50(weights='imagenet', input_tensor=myinput, include_top=False)\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "# this is the model we will train\n",
    "model = Model(myinput, predictions)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "best_model = ModelCheckpoint('model_best.h5', verbose=1, save_best_only=True)\n",
    "model.fit(train_x, train_y, validation_split=0.2, shuffle=True, batch_size=16, epochs=10, callbacks=[best_model])\n",
    "model.save('model_10.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------------------------------------------------------------------------------------------------------\n",
    "### 75% Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "19984/20000 [============================>.] - ETA: 3s - loss: 0.2106 - acc: 0.9092\n",
      "Epoch 00001: val_loss improved from inf to 0.05018, saving model to model_best.h5\n",
      "20000/20000 [==============================] - 5164s 258ms/step - loss: 0.2105 - acc: 0.9092 - val_loss: 0.0502 - val_acc: 0.9854\n",
      "Epoch 2/10\n",
      "19984/20000 [============================>.] - ETA: 3s - loss: 0.0819 - acc: 0.9699\n",
      "Epoch 00002: val_loss improved from 0.05018 to 0.03850, saving model to model_best.h5\n",
      "20000/20000 [==============================] - 5244s 262ms/step - loss: 0.0819 - acc: 0.9699 - val_loss: 0.0385 - val_acc: 0.9872\n",
      "Epoch 3/10\n",
      "19984/20000 [============================>.] - ETA: 3s - loss: 0.0610 - acc: 0.9772\n",
      "Epoch 00003: val_loss improved from 0.03850 to 0.03489, saving model to model_best.h5\n",
      "20000/20000 [==============================] - 5178s 259ms/step - loss: 0.0610 - acc: 0.9771 - val_loss: 0.0349 - val_acc: 0.9880\n",
      "Epoch 4/10\n",
      "19984/20000 [============================>.] - ETA: 3s - loss: 0.0456 - acc: 0.9841\n",
      "Epoch 00004: val_loss improved from 0.03489 to 0.03298, saving model to model_best.h5\n",
      "20000/20000 [==============================] - 5251s 263ms/step - loss: 0.0456 - acc: 0.9841 - val_loss: 0.0330 - val_acc: 0.9886\n",
      "Epoch 5/10\n",
      "19984/20000 [============================>.] - ETA: 3s - loss: 0.0371 - acc: 0.9865\n",
      "Epoch 00005: val_loss improved from 0.03298 to 0.03106, saving model to model_best.h5\n",
      "20000/20000 [==============================] - 5050s 252ms/step - loss: 0.0372 - acc: 0.9865 - val_loss: 0.0311 - val_acc: 0.9890\n",
      "Epoch 6/10\n",
      "19984/20000 [============================>.] - ETA: 3s - loss: 0.0315 - acc: 0.9885\n",
      "Epoch 00006: val_loss improved from 0.03106 to 0.03022, saving model to model_best.h5\n",
      "20000/20000 [==============================] - 5065s 253ms/step - loss: 0.0315 - acc: 0.9886 - val_loss: 0.0302 - val_acc: 0.9898\n",
      "Epoch 7/10\n",
      "19984/20000 [============================>.] - ETA: 3s - loss: 0.0263 - acc: 0.9909\n",
      "Epoch 00007: val_loss improved from 0.03022 to 0.02980, saving model to model_best.h5\n",
      "20000/20000 [==============================] - 5122s 256ms/step - loss: 0.0263 - acc: 0.9909 - val_loss: 0.0298 - val_acc: 0.9902\n",
      "Epoch 8/10\n",
      "19984/20000 [============================>.] - ETA: 3s - loss: 0.0213 - acc: 0.9923\n",
      "Epoch 00008: val_loss improved from 0.02980 to 0.02937, saving model to model_best.h5\n",
      "20000/20000 [==============================] - 5072s 254ms/step - loss: 0.0215 - acc: 0.9922 - val_loss: 0.0294 - val_acc: 0.9906\n",
      "Epoch 9/10\n",
      "19984/20000 [============================>.] - ETA: 3s - loss: 0.0185 - acc: 0.9931\n",
      "Epoch 00009: val_loss did not improve\n",
      "20000/20000 [==============================] - 5049s 252ms/step - loss: 0.0185 - acc: 0.9931 - val_loss: 0.0297 - val_acc: 0.9896\n",
      "Epoch 10/10\n",
      "19984/20000 [============================>.] - ETA: 3s - loss: 0.0164 - acc: 0.9948\n",
      "Epoch 00010: val_loss did not improve\n",
      "20000/20000 [==============================] - 4931s 247ms/step - loss: 0.0163 - acc: 0.9948 - val_loss: 0.0301 - val_acc: 0.9906\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "opt = SGD(lr=0.0001, momentum=0.9)\n",
    "myinput = Input(shape=(224, 224, 3))\n",
    "base_model = ResNet50(weights='imagenet', input_tensor=myinput, include_top=False)\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.75)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "# this is the model we will train\n",
    "model = Model(myinput, predictions)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "best_model = ModelCheckpoint('model_best.h5', verbose=1, save_best_only=True)\n",
    "model.fit(train_x, train_y, validation_split=0.2, shuffle=True, batch_size=16, epochs=10, callbacks=[best_model])\n",
    "model.save('model_10.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## ------------------------------------------------------------------------------------------------------\n",
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\\cat.10029.jpg\n",
      "cat\\cat.10266.jpg\n",
      "cat\\cat.10610.jpg\n",
      "cat\\cat.10712.jpg\n",
      "cat\\cat.11184.jpg\n",
      "cat\\cat.11222.jpg\n",
      "cat\\cat.11281.jpg\n",
      "cat\\cat.11565.jpg\n",
      "cat\\cat.12272.jpg\n",
      "cat\\cat.12499.jpg\n",
      "cat\\cat.1361.jpg\n",
      "cat\\cat.1962.jpg\n",
      "cat\\cat.2337.jpg\n",
      "cat\\cat.3202.jpg\n",
      "cat\\cat.3658.jpg\n",
      "cat\\cat.4085.jpg\n",
      "cat\\cat.4308.jpg\n",
      "cat\\cat.4360.jpg\n",
      "cat\\cat.4688.jpg\n",
      "cat\\cat.4986.jpg\n",
      "cat\\cat.5355.jpg\n",
      "cat\\cat.5418.jpg\n",
      "cat\\cat.5583.jpg\n",
      "cat\\cat.5795.jpg\n",
      "cat\\cat.5834.jpg\n",
      "cat\\cat.6304.jpg\n",
      "cat\\cat.6402.jpg\n",
      "cat\\cat.6655.jpg\n",
      "cat\\cat.7564.jpg\n",
      "cat\\cat.7655.jpg\n",
      "cat\\cat.7671.jpg\n",
      "cat\\cat.7703.jpg\n",
      "cat\\cat.7920.jpg\n",
      "cat\\cat.7968.jpg\n",
      "cat\\cat.8138.jpg\n",
      "cat\\cat.8456.jpg\n",
      "cat\\cat.8504.jpg\n",
      "cat\\cat.8828.jpg\n",
      "cat\\cat.9290.jpg\n",
      "cat\\cat.9596.jpg\n",
      "cat\\cat.9897.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "size = 224\n",
    "model_test = load_model('model_best.h5')\n",
    "cat_dir = glob.glob('cat/*.jpg')\n",
    "for file_name in cat_dir:        \n",
    "    img = image.load_img(file_name, target_size=(size, size))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    if model_test.predict(x) > 0.5:\n",
    "        print(file_name)\n",
    "        os.remove(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\\dog.10225.jpg\n",
      "dog\\dog.10524.jpg\n",
      "dog\\dog.10801.jpg\n",
      "dog\\dog.10939.jpg\n",
      "dog\\dog.11299.jpg\n",
      "dog\\dog.11300.jpg\n",
      "dog\\dog.11526.jpg\n",
      "dog\\dog.11731.jpg\n",
      "dog\\dog.12223.jpg\n",
      "dog\\dog.2614.jpg\n",
      "dog\\dog.3074.jpg\n",
      "dog\\dog.3341.jpg\n",
      "dog\\dog.3920.jpg\n",
      "dog\\dog.4334.jpg\n",
      "dog\\dog.4690.jpg\n",
      "dog\\dog.5251.jpg\n",
      "dog\\dog.5529.jpg\n",
      "dog\\dog.5767.jpg\n",
      "dog\\dog.6256.jpg\n",
      "dog\\dog.6921.jpg\n",
      "dog\\dog.7.jpg\n",
      "dog\\dog.7076.jpg\n",
      "dog\\dog.7332.jpg\n",
      "dog\\dog.7413.jpg\n",
      "dog\\dog.7692.jpg\n",
      "dog\\dog.8671.jpg\n",
      "dog\\dog.9517.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "size = 224\n",
    "model_test = load_model('model_best.h5')\n",
    "dog_dir = glob.glob('dog/*.jpg')\n",
    "for file_name in dog_dir:        \n",
    "    img = image.load_img(file_name, target_size=(size, size))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    if model_test.predict(x) < 0.5:\n",
    "        print(file_name)\n",
    "        os.remove(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean file to file name clean_train and train once more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File operation begin !\n",
      "file operation to clean_train done! 21.35 second spented\n"
     ]
    }
   ],
   "source": [
    "print('File operation begin !')\n",
    "t=time.time()\n",
    "clean_dog_files = os.listdir(DOG_PATH)\n",
    "clean_cat_files = os.listdir(CAT_PATH)\n",
    "for file in clean_dog_files:\n",
    "    shutil.copy(DOG_PATH + file, CLEAN_TRAIN + file)\n",
    "for file in clean_cat_files:\n",
    "    shutil.copy(CAT_PATH + file, CLEAN_TRAIN + file)\n",
    "t2 = time.time()\n",
    "print('file operation to clean_train done!', round(t2 - t, 2), 'second spented')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------------------------------------------------------------------------------------------------------\n",
    "### 75% Dropout Retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proprecessing begin !\n",
      "1170.75 seconds to preprocessing !\n"
     ]
    }
   ],
   "source": [
    "# cat 0  dog 1\n",
    "print('Proprecessing begin !')\n",
    "t=time.time()\n",
    "train_dir = glob.glob('clean_train/*.jpg')\n",
    "train_x, train_y = get_train_data1(train_dir)\n",
    "t2 = time.time()\n",
    "print(round(t2 - t, 2), 'seconds to preprocessing !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19945 samples, validate on 4987 samples\n",
      "Epoch 1/10\n",
      "19936/19945 [============================>.] - ETA: 2s - loss: 0.1761 - acc: 0.9323\n",
      "Epoch 00001: val_loss improved from inf to 0.04538, saving model to model_best.h5\n",
      "19945/19945 [==============================] - 5182s 260ms/step - loss: 0.1762 - acc: 0.9323 - val_loss: 0.0454 - val_acc: 0.9880\n",
      "Epoch 2/10\n",
      "19936/19945 [============================>.] - ETA: 2s - loss: 0.0691 - acc: 0.9755\n",
      "Epoch 00002: val_loss improved from 0.04538 to 0.03252, saving model to model_best.h5\n",
      "19945/19945 [==============================] - 5002s 251ms/step - loss: 0.0691 - acc: 0.9755 - val_loss: 0.0325 - val_acc: 0.9908\n",
      "Epoch 3/10\n",
      "19936/19945 [============================>.] - ETA: 2s - loss: 0.0515 - acc: 0.9810\n",
      "Epoch 00003: val_loss improved from 0.03252 to 0.02635, saving model to model_best.h5\n",
      "19945/19945 [==============================] - 5040s 253ms/step - loss: 0.0515 - acc: 0.9810 - val_loss: 0.0264 - val_acc: 0.9916\n",
      "Epoch 4/10\n",
      "19936/19945 [============================>.] - ETA: 2s - loss: 0.0395 - acc: 0.9854\n",
      "Epoch 00004: val_loss improved from 0.02635 to 0.02282, saving model to model_best.h5\n",
      "19945/19945 [==============================] - 4993s 250ms/step - loss: 0.0395 - acc: 0.9854 - val_loss: 0.0228 - val_acc: 0.9918\n",
      "Epoch 5/10\n",
      "19936/19945 [============================>.] - ETA: 2s - loss: 0.0311 - acc: 0.9888\n",
      "Epoch 00005: val_loss improved from 0.02282 to 0.02017, saving model to model_best.h5\n",
      "19945/19945 [==============================] - 6052s 303ms/step - loss: 0.0311 - acc: 0.9888 - val_loss: 0.0202 - val_acc: 0.9928\n",
      "Epoch 6/10\n",
      "19936/19945 [============================>.] - ETA: 2s - loss: 0.0237 - acc: 0.9920\n",
      "Epoch 00006: val_loss improved from 0.02017 to 0.01880, saving model to model_best.h5\n",
      "19945/19945 [==============================] - 5140s 258ms/step - loss: 0.0237 - acc: 0.9920 - val_loss: 0.0188 - val_acc: 0.9936\n",
      "Epoch 7/10\n",
      "19936/19945 [============================>.] - ETA: 2s - loss: 0.0218 - acc: 0.9919\n",
      "Epoch 00007: val_loss did not improve\n",
      "19945/19945 [==============================] - 5105s 256ms/step - loss: 0.0218 - acc: 0.9919 - val_loss: 0.0189 - val_acc: 0.9930\n",
      "Epoch 8/10\n",
      "19936/19945 [============================>.] - ETA: 2s - loss: 0.0199 - acc: 0.9929\n",
      "Epoch 00008: val_loss improved from 0.01880 to 0.01825, saving model to model_best.h5\n",
      "19945/19945 [==============================] - 5025s 252ms/step - loss: 0.0199 - acc: 0.9929 - val_loss: 0.0183 - val_acc: 0.9934\n",
      "Epoch 9/10\n",
      "19936/19945 [============================>.] - ETA: 2s - loss: 0.0162 - acc: 0.9948\n",
      "Epoch 00009: val_loss did not improve\n",
      "19945/19945 [==============================] - 5006s 251ms/step - loss: 0.0162 - acc: 0.9948 - val_loss: 0.0190 - val_acc: 0.9928\n",
      "Epoch 10/10\n",
      "19936/19945 [============================>.] - ETA: 2s - loss: 0.0139 - acc: 0.9959\n",
      "Epoch 00010: val_loss improved from 0.01825 to 0.01776, saving model to model_best.h5\n",
      "19945/19945 [==============================] - 5039s 253ms/step - loss: 0.0139 - acc: 0.9958 - val_loss: 0.0178 - val_acc: 0.9932\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "opt = SGD(lr=0.0001, momentum=0.9)\n",
    "myinput = Input(shape=(224, 224, 3))\n",
    "base_model = ResNet50(weights='imagenet', input_tensor=myinput, include_top=False)\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.75)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "# this is the model we will train\n",
    "model = Model(myinput, predictions)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "best_model = ModelCheckpoint('model_best.h5', verbose=1, save_best_only=True)\n",
    "model.fit(train_x, train_y, validation_split=0.2, shuffle=True, batch_size=16, epochs=10, callbacks=[best_model])\n",
    "model.save('model_10.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## ------------------------------------------------------------------------------------------------------\n",
    "### Drawing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('model_best.h5')\n",
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file='model_display.png',show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------------------------------------------------------------------------------------------------------\n",
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "size = 224\n",
    "test_dir = glob.glob('test/*.jpg')\n",
    "mytest = np.zeros((12500, size, size, 3), dtype=np.float32)\n",
    "for file_name in (test_dir):\n",
    "    index = int(file_name[6:-4]) - 1\n",
    "    img = image.load_img(file_name, target_size=(size, size))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    mytest[index] = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------------------------------------------------------------------------------------------------------\n",
    "### Write in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##predict\n",
    "with open('file_result.csv','w') as f:\n",
    "    f.write('id,label\\n')\n",
    "\n",
    "model_test = load_model('model_best.h5')\n",
    "\n",
    "with open('file_result.csv','a') as f:\n",
    "    for i in range(len(test_dir)):\n",
    "        predict = model_test.predict(mytest[i:i+1])\n",
    "        predict = predict[0][0]\n",
    "        f.write('{},{}\\n'.format(i+1,predict))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
