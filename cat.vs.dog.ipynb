{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文件操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File operation begin !\n",
      "File done 24.89 seconds to operation !\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil \n",
    "import random\n",
    "import time\n",
    "print('File operation begin !')\n",
    "t=time.time()\n",
    "TRAIN_PATH = \"./train/\"\n",
    "TEST_PATH = \"./test/\"\n",
    "# SAMPLE_PATH = \"sample/\"\n",
    "CAT_PATH = \"cat/\"\n",
    "DOG_PATH = \"dog/\"\n",
    "CLEAN_TRAIN = \"clean_train/\"\n",
    "\n",
    "def checkDir(dir_path):\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "\n",
    "checkDir(CAT_PATH)\n",
    "checkDir(DOG_PATH)\n",
    "checkDir(CLEAN_TRAIN)\n",
    "\n",
    "train_files = os.listdir(TRAIN_PATH)\n",
    "for file in train_files:\n",
    "    if 'dog' in file:\n",
    "        shutil.copy(TRAIN_PATH + file, DOG_PATH + file)\n",
    "    if 'cat' in file:\n",
    "        shutil.copy(TRAIN_PATH + file, CAT_PATH + file)    \n",
    "t2 = time.time()\n",
    "print('File done', round(t2 - t, 2), 'seconds to operation !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kiddiebao/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pylab as plb\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Dropout, Dense\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.utils import shuffle\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  数据可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "for file in train_files:\n",
    "    img = cv2.imread(TRAIN_PATH + file)\n",
    "    imgs.append(img.shape[0:2])\n",
    "#     break\n",
    "    \n",
    "imgs = np.array(imgs)\n",
    "x = imgs[:,0]\n",
    "y = imgs[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d8ea630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "plt.title('cat-width-height')\n",
    "plt.xlabel('Width')\n",
    "plt.ylabel('Height')\n",
    "plt.scatter(x, y, alpha = 0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自带的预处理方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data1(imgDir, size=224):\n",
    "    imgDir = shuffle(imgDir)\n",
    "    train_x = np.zeros((len(imgDir), size, size, 3), dtype=np.float32)\n",
    "    train_y = np.zeros(len(imgDir), dtype=np.uint8)\n",
    "    for index, file in enumerate(imgDir):        \n",
    "        img = image.load_img(file, target_size=(size, size))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        train_x[index] = preprocess_input(x)    \n",
    "        if 'dog' in file:\n",
    "            train_y[index] = 1\n",
    "    return train_x, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proprecessing begin !\n",
      "1215.41 seconds to preprocessing !\n"
     ]
    }
   ],
   "source": [
    "# cat 0  dog 1\n",
    "print('Proprecessing begin !')\n",
    "t=time.time()\n",
    "train_dir = glob.glob('train_all/*.jpg')\n",
    "train_x, train_y = get_train_data1(train_dir)\n",
    "t2 = time.time()\n",
    "print(round(t2 - t, 2), 'seconds to preprocessing !')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------------------------------------------------------------------------------------------------------\n",
    "### 50% Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "19990/20000 [============================>.] - ETA: 2s - loss: 0.1564 - acc: 0.9376\n",
      "Epoch 00001: val_loss improved from inf to 0.04456, saving model to model_best.h5\n",
      "20000/20000 [==============================] - 5523s 276ms/step - loss: 0.1564 - acc: 0.9375 - val_loss: 0.0446 - val_acc: 0.9854\n",
      "Epoch 2/10\n",
      "19990/20000 [============================>.] - ETA: 2s - loss: 0.0777 - acc: 0.9699\n",
      "Epoch 00002: val_loss improved from 0.04456 to 0.03630, saving model to model_best.h5\n",
      "20000/20000 [==============================] - 5346s 267ms/step - loss: 0.0777 - acc: 0.9699 - val_loss: 0.0363 - val_acc: 0.9872\n",
      "Epoch 3/10\n",
      "19990/20000 [============================>.] - ETA: 2s - loss: 0.0541 - acc: 0.9809\n",
      "Epoch 00003: val_loss improved from 0.03630 to 0.03114, saving model to model_best.h5\n",
      "20000/20000 [==============================] - 5357s 268ms/step - loss: 0.0541 - acc: 0.9809 - val_loss: 0.0311 - val_acc: 0.9892\n",
      "Epoch 4/10\n",
      "19990/20000 [============================>.] - ETA: 2s - loss: 0.0420 - acc: 0.9854\n",
      "Epoch 00004: val_loss improved from 0.03114 to 0.03020, saving model to model_best.h5\n",
      "20000/20000 [==============================] - 5645s 282ms/step - loss: 0.0419 - acc: 0.9854 - val_loss: 0.0302 - val_acc: 0.9900\n",
      "Epoch 5/10\n",
      "19990/20000 [============================>.] - ETA: 2s - loss: 0.0328 - acc: 0.9883\n",
      "Epoch 00005: val_loss improved from 0.03020 to 0.02960, saving model to model_best.h5\n",
      "20000/20000 [==============================] - 5445s 272ms/step - loss: 0.0328 - acc: 0.9883 - val_loss: 0.0296 - val_acc: 0.9900\n",
      "Epoch 6/10\n",
      "19990/20000 [============================>.] - ETA: 2s - loss: 0.0278 - acc: 0.9905\n",
      "Epoch 00006: val_loss did not improve\n",
      "20000/20000 [==============================] - 5308s 265ms/step - loss: 0.0278 - acc: 0.9905 - val_loss: 0.0302 - val_acc: 0.9894\n",
      "Epoch 7/10\n",
      "19990/20000 [============================>.] - ETA: 2s - loss: 0.0199 - acc: 0.9933\n",
      "Epoch 00007: val_loss improved from 0.02960 to 0.02953, saving model to model_best.h5\n",
      "20000/20000 [==============================] - 5321s 266ms/step - loss: 0.0199 - acc: 0.9933 - val_loss: 0.0295 - val_acc: 0.9898\n",
      "Epoch 8/10\n",
      "19990/20000 [============================>.] - ETA: 2s - loss: 0.0167 - acc: 0.9943\n",
      "Epoch 00008: val_loss improved from 0.02953 to 0.02855, saving model to model_best.h5\n",
      "20000/20000 [==============================] - 5297s 265ms/step - loss: 0.0167 - acc: 0.9943 - val_loss: 0.0285 - val_acc: 0.9902\n",
      "Epoch 9/10\n",
      "19990/20000 [============================>.] - ETA: 2s - loss: 0.0159 - acc: 0.9947\n",
      "Epoch 00009: val_loss did not improve\n",
      "20000/20000 [==============================] - 5276s 264ms/step - loss: 0.0159 - acc: 0.9947 - val_loss: 0.0290 - val_acc: 0.9894\n",
      "Epoch 10/10\n",
      "19990/20000 [============================>.] - ETA: 2s - loss: 0.0128 - acc: 0.9963\n",
      "Epoch 00010: val_loss did not improve\n",
      "20000/20000 [==============================] - 5289s 264ms/step - loss: 0.0128 - acc: 0.9963 - val_loss: 0.0286 - val_acc: 0.9898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a27e3584a8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "opt = SGD(lr=0.0001, momentum=0.9)\n",
    "myinput = Input(shape=(224, 224, 3))\n",
    "base_model = ResNet50(weights='imagenet', input_tensor=myinput, include_top=False)\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "# this is the model we will train\n",
    "model = Model(myinput, predictions)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "best_model = ModelCheckpoint('model_best.h5', verbose=1, save_best_only=True)\n",
    "model.fit(train_x, train_y, validation_split=0.2, shuffle=True, batch_size=16, epochs=10, callbacks=[best_model])\n",
    "model.save('model_10.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------------------------------------------------------------------------------------------------------\n",
    "### 75% Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "19984/20000 [============================>.] - ETA: 3s - loss: 0.2106 - acc: 0.9092\n",
      "Epoch 00001: val_loss improved from inf to 0.05018, saving model to model_best.h5\n",
      "20000/20000 [==============================] - 5164s 258ms/step - loss: 0.2105 - acc: 0.9092 - val_loss: 0.0502 - val_acc: 0.9854\n",
      "Epoch 2/10\n",
      "19984/20000 [============================>.] - ETA: 3s - loss: 0.0819 - acc: 0.9699\n",
      "Epoch 00002: val_loss improved from 0.05018 to 0.03850, saving model to model_best.h5\n",
      "20000/20000 [==============================] - 5244s 262ms/step - loss: 0.0819 - acc: 0.9699 - val_loss: 0.0385 - val_acc: 0.9872\n",
      "Epoch 3/10\n",
      "19984/20000 [============================>.] - ETA: 3s - loss: 0.0610 - acc: 0.9772\n",
      "Epoch 00003: val_loss improved from 0.03850 to 0.03489, saving model to model_best.h5\n",
      "20000/20000 [==============================] - 5178s 259ms/step - loss: 0.0610 - acc: 0.9771 - val_loss: 0.0349 - val_acc: 0.9880\n",
      "Epoch 4/10\n",
      "19984/20000 [============================>.] - ETA: 3s - loss: 0.0456 - acc: 0.9841\n",
      "Epoch 00004: val_loss improved from 0.03489 to 0.03298, saving model to model_best.h5\n",
      "20000/20000 [==============================] - 5251s 263ms/step - loss: 0.0456 - acc: 0.9841 - val_loss: 0.0330 - val_acc: 0.9886\n",
      "Epoch 5/10\n",
      "19984/20000 [============================>.] - ETA: 3s - loss: 0.0371 - acc: 0.9865\n",
      "Epoch 00005: val_loss improved from 0.03298 to 0.03106, saving model to model_best.h5\n",
      "20000/20000 [==============================] - 5050s 252ms/step - loss: 0.0372 - acc: 0.9865 - val_loss: 0.0311 - val_acc: 0.9890\n",
      "Epoch 6/10\n",
      "19984/20000 [============================>.] - ETA: 3s - loss: 0.0315 - acc: 0.9885\n",
      "Epoch 00006: val_loss improved from 0.03106 to 0.03022, saving model to model_best.h5\n",
      "20000/20000 [==============================] - 5065s 253ms/step - loss: 0.0315 - acc: 0.9886 - val_loss: 0.0302 - val_acc: 0.9898\n",
      "Epoch 7/10\n",
      "19984/20000 [============================>.] - ETA: 3s - loss: 0.0263 - acc: 0.9909\n",
      "Epoch 00007: val_loss improved from 0.03022 to 0.02980, saving model to model_best.h5\n",
      "20000/20000 [==============================] - 5122s 256ms/step - loss: 0.0263 - acc: 0.9909 - val_loss: 0.0298 - val_acc: 0.9902\n",
      "Epoch 8/10\n",
      "19984/20000 [============================>.] - ETA: 3s - loss: 0.0213 - acc: 0.9923\n",
      "Epoch 00008: val_loss improved from 0.02980 to 0.02937, saving model to model_best.h5\n",
      "20000/20000 [==============================] - 5072s 254ms/step - loss: 0.0215 - acc: 0.9922 - val_loss: 0.0294 - val_acc: 0.9906\n",
      "Epoch 9/10\n",
      "19984/20000 [============================>.] - ETA: 3s - loss: 0.0185 - acc: 0.9931\n",
      "Epoch 00009: val_loss did not improve\n",
      "20000/20000 [==============================] - 5049s 252ms/step - loss: 0.0185 - acc: 0.9931 - val_loss: 0.0297 - val_acc: 0.9896\n",
      "Epoch 10/10\n",
      "19984/20000 [============================>.] - ETA: 3s - loss: 0.0164 - acc: 0.9948\n",
      "Epoch 00010: val_loss did not improve\n",
      "20000/20000 [==============================] - 4931s 247ms/step - loss: 0.0163 - acc: 0.9948 - val_loss: 0.0301 - val_acc: 0.9906\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "opt = SGD(lr=0.0001, momentum=0.9)\n",
    "myinput = Input(shape=(224, 224, 3))\n",
    "base_model = ResNet50(weights='imagenet', input_tensor=myinput, include_top=False)\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.75)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "# this is the model we will train\n",
    "model = Model(myinput, predictions)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "best_model = ModelCheckpoint('model_best.h5', verbose=1, save_best_only=True)\n",
    "model.fit(train_x, train_y, validation_split=0.2, shuffle=True, batch_size=16, epochs=10, callbacks=[best_model])\n",
    "model.save('model_10.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## ------------------------------------------------------------------------------------------------------\n",
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\\cat.10029.jpg\n",
      "cat\\cat.10266.jpg\n",
      "cat\\cat.10610.jpg\n",
      "cat\\cat.10712.jpg\n",
      "cat\\cat.11184.jpg\n",
      "cat\\cat.11222.jpg\n",
      "cat\\cat.11281.jpg\n",
      "cat\\cat.11565.jpg\n",
      "cat\\cat.12272.jpg\n",
      "cat\\cat.12499.jpg\n",
      "cat\\cat.1361.jpg\n",
      "cat\\cat.1962.jpg\n",
      "cat\\cat.2337.jpg\n",
      "cat\\cat.3202.jpg\n",
      "cat\\cat.3658.jpg\n",
      "cat\\cat.4085.jpg\n",
      "cat\\cat.4308.jpg\n",
      "cat\\cat.4360.jpg\n",
      "cat\\cat.4688.jpg\n",
      "cat\\cat.4986.jpg\n",
      "cat\\cat.5355.jpg\n",
      "cat\\cat.5418.jpg\n",
      "cat\\cat.5583.jpg\n",
      "cat\\cat.5795.jpg\n",
      "cat\\cat.5834.jpg\n",
      "cat\\cat.6304.jpg\n",
      "cat\\cat.6402.jpg\n",
      "cat\\cat.6655.jpg\n",
      "cat\\cat.7564.jpg\n",
      "cat\\cat.7655.jpg\n",
      "cat\\cat.7671.jpg\n",
      "cat\\cat.7703.jpg\n",
      "cat\\cat.7920.jpg\n",
      "cat\\cat.7968.jpg\n",
      "cat\\cat.8138.jpg\n",
      "cat\\cat.8456.jpg\n",
      "cat\\cat.8504.jpg\n",
      "cat\\cat.8828.jpg\n",
      "cat\\cat.9290.jpg\n",
      "cat\\cat.9596.jpg\n",
      "cat\\cat.9897.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "size = 224\n",
    "model_test = load_model('model_best.h5')\n",
    "cat_dir = glob.glob('cat/*.jpg')\n",
    "for file_name in cat_dir:        \n",
    "    img = image.load_img(file_name, target_size=(size, size))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    if model_test.predict(x) > 0.5:\n",
    "        print(file_name)\n",
    "        os.remove(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\\dog.10225.jpg\n",
      "dog\\dog.10524.jpg\n",
      "dog\\dog.10801.jpg\n",
      "dog\\dog.10939.jpg\n",
      "dog\\dog.11299.jpg\n",
      "dog\\dog.11300.jpg\n",
      "dog\\dog.11526.jpg\n",
      "dog\\dog.11731.jpg\n",
      "dog\\dog.12223.jpg\n",
      "dog\\dog.2614.jpg\n",
      "dog\\dog.3074.jpg\n",
      "dog\\dog.3341.jpg\n",
      "dog\\dog.3920.jpg\n",
      "dog\\dog.4334.jpg\n",
      "dog\\dog.4690.jpg\n",
      "dog\\dog.5251.jpg\n",
      "dog\\dog.5529.jpg\n",
      "dog\\dog.5767.jpg\n",
      "dog\\dog.6256.jpg\n",
      "dog\\dog.6921.jpg\n",
      "dog\\dog.7.jpg\n",
      "dog\\dog.7076.jpg\n",
      "dog\\dog.7332.jpg\n",
      "dog\\dog.7413.jpg\n",
      "dog\\dog.7692.jpg\n",
      "dog\\dog.8671.jpg\n",
      "dog\\dog.9517.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "size = 224\n",
    "model_test = load_model('model_best.h5')\n",
    "dog_dir = glob.glob('dog/*.jpg')\n",
    "for file_name in dog_dir:        \n",
    "    img = image.load_img(file_name, target_size=(size, size))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    if model_test.predict(x) < 0.5:\n",
    "        print(file_name)\n",
    "        os.remove(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean file to file name clean_train and train once more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File operation begin !\n",
      "file operation to clean_train done! 21.35 second spented\n"
     ]
    }
   ],
   "source": [
    "print('File operation begin !')\n",
    "t=time.time()\n",
    "clean_dog_files = os.listdir(DOG_PATH)\n",
    "clean_cat_files = os.listdir(CAT_PATH)\n",
    "for file in clean_dog_files:\n",
    "    shutil.copy(DOG_PATH + file, CLEAN_TRAIN + file)\n",
    "for file in clean_cat_files:\n",
    "    shutil.copy(CAT_PATH + file, CLEAN_TRAIN + file)\n",
    "t2 = time.time()\n",
    "print('file operation to clean_train done!', round(t2 - t, 2), 'second spented')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------------------------------------------------------------------------------------------------------\n",
    "### 75% Dropout Retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proprecessing begin !\n",
      "1170.75 seconds to preprocessing !\n"
     ]
    }
   ],
   "source": [
    "# cat 0  dog 1\n",
    "print('Proprecessing begin !')\n",
    "t=time.time()\n",
    "train_dir = glob.glob('clean_train/*.jpg')\n",
    "train_x, train_y = get_train_data1(train_dir)\n",
    "t2 = time.time()\n",
    "print(round(t2 - t, 2), 'seconds to preprocessing !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19945 samples, validate on 4987 samples\n",
      "Epoch 1/10\n",
      "19936/19945 [============================>.] - ETA: 2s - loss: 0.1761 - acc: 0.9323\n",
      "Epoch 00001: val_loss improved from inf to 0.04538, saving model to model_best.h5\n",
      "19945/19945 [==============================] - 5182s 260ms/step - loss: 0.1762 - acc: 0.9323 - val_loss: 0.0454 - val_acc: 0.9880\n",
      "Epoch 2/10\n",
      "19936/19945 [============================>.] - ETA: 2s - loss: 0.0691 - acc: 0.9755\n",
      "Epoch 00002: val_loss improved from 0.04538 to 0.03252, saving model to model_best.h5\n",
      "19945/19945 [==============================] - 5002s 251ms/step - loss: 0.0691 - acc: 0.9755 - val_loss: 0.0325 - val_acc: 0.9908\n",
      "Epoch 3/10\n",
      "19936/19945 [============================>.] - ETA: 2s - loss: 0.0515 - acc: 0.9810\n",
      "Epoch 00003: val_loss improved from 0.03252 to 0.02635, saving model to model_best.h5\n",
      "19945/19945 [==============================] - 5040s 253ms/step - loss: 0.0515 - acc: 0.9810 - val_loss: 0.0264 - val_acc: 0.9916\n",
      "Epoch 4/10\n",
      "19936/19945 [============================>.] - ETA: 2s - loss: 0.0395 - acc: 0.9854\n",
      "Epoch 00004: val_loss improved from 0.02635 to 0.02282, saving model to model_best.h5\n",
      "19945/19945 [==============================] - 4993s 250ms/step - loss: 0.0395 - acc: 0.9854 - val_loss: 0.0228 - val_acc: 0.9918\n",
      "Epoch 5/10\n",
      "19936/19945 [============================>.] - ETA: 2s - loss: 0.0311 - acc: 0.9888\n",
      "Epoch 00005: val_loss improved from 0.02282 to 0.02017, saving model to model_best.h5\n",
      "19945/19945 [==============================] - 6052s 303ms/step - loss: 0.0311 - acc: 0.9888 - val_loss: 0.0202 - val_acc: 0.9928\n",
      "Epoch 6/10\n",
      "19936/19945 [============================>.] - ETA: 2s - loss: 0.0237 - acc: 0.9920\n",
      "Epoch 00006: val_loss improved from 0.02017 to 0.01880, saving model to model_best.h5\n",
      "19945/19945 [==============================] - 5140s 258ms/step - loss: 0.0237 - acc: 0.9920 - val_loss: 0.0188 - val_acc: 0.9936\n",
      "Epoch 7/10\n",
      "19936/19945 [============================>.] - ETA: 2s - loss: 0.0218 - acc: 0.9919\n",
      "Epoch 00007: val_loss did not improve\n",
      "19945/19945 [==============================] - 5105s 256ms/step - loss: 0.0218 - acc: 0.9919 - val_loss: 0.0189 - val_acc: 0.9930\n",
      "Epoch 8/10\n",
      "19936/19945 [============================>.] - ETA: 2s - loss: 0.0199 - acc: 0.9929\n",
      "Epoch 00008: val_loss improved from 0.01880 to 0.01825, saving model to model_best.h5\n",
      "19945/19945 [==============================] - 5025s 252ms/step - loss: 0.0199 - acc: 0.9929 - val_loss: 0.0183 - val_acc: 0.9934\n",
      "Epoch 9/10\n",
      "19936/19945 [============================>.] - ETA: 2s - loss: 0.0162 - acc: 0.9948\n",
      "Epoch 00009: val_loss did not improve\n",
      "19945/19945 [==============================] - 5006s 251ms/step - loss: 0.0162 - acc: 0.9948 - val_loss: 0.0190 - val_acc: 0.9928\n",
      "Epoch 10/10\n",
      "19936/19945 [============================>.] - ETA: 2s - loss: 0.0139 - acc: 0.9959\n",
      "Epoch 00010: val_loss improved from 0.01825 to 0.01776, saving model to model_best.h5\n",
      "19945/19945 [==============================] - 5039s 253ms/step - loss: 0.0139 - acc: 0.9958 - val_loss: 0.0178 - val_acc: 0.9932\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "opt = SGD(lr=0.0001, momentum=0.9)\n",
    "myinput = Input(shape=(224, 224, 3))\n",
    "base_model = ResNet50(weights='imagenet', input_tensor=myinput, include_top=False)\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.75)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "# this is the model we will train\n",
    "model = Model(myinput, predictions)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "best_model = ModelCheckpoint('model_best.h5', verbose=1, save_best_only=True)\n",
    "model.fit(train_x, train_y, validation_split=0.2, shuffle=True, batch_size=16, epochs=10, callbacks=[best_model])\n",
    "model.save('model_10.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## ------------------------------------------------------------------------------------------------------\n",
    "### Drawing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('model_best.h5')\n",
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file='model_display.png',show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------------------------------------------------------------------------------------------------------\n",
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "size = 224\n",
    "test_dir = glob.glob('test/*.jpg')\n",
    "mytest = np.zeros((12500, size, size, 3), dtype=np.float32)\n",
    "for file_name in (test_dir):\n",
    "    index = int(file_name[6:-4]) - 1\n",
    "    img = image.load_img(file_name, target_size=(size, size))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    mytest[index] = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------------------------------------------------------------------------------------------------------\n",
    "### Write in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##predict\n",
    "with open('file_result.csv','w') as f:\n",
    "    f.write('id,label\\n')\n",
    "\n",
    "model_test = load_model('model_best.h5')\n",
    "\n",
    "with open('file_result.csv','a') as f:\n",
    "    for i in range(len(test_dir)):\n",
    "        predict = model_test.predict(mytest[i:i+1])\n",
    "        predict = predict[0][0]\n",
    "        f.write('{},{}\\n'.format(i+1,predict))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
