{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs = [\n",
    " 'n02085620','n02085782','n02085936','n02086079'\n",
    ",'n02086240','n02086646','n02086910','n02087046'\n",
    ",'n02087394','n02088094','n02088238','n02088364'\n",
    ",'n02088466','n02088632','n02089078','n02089867'\n",
    ",'n02089973','n02090379','n02090622','n02090721'\n",
    ",'n02091032','n02091134','n02091244','n02091467'\n",
    ",'n02091635','n02091831','n02092002','n02092339'\n",
    ",'n02093256','n02093428','n02093647','n02093754'\n",
    ",'n02093859','n02093991','n02094114','n02094258'\n",
    ",'n02094433','n02095314','n02095570','n02095889'\n",
    ",'n02096051','n02096177','n02096294','n02096437'\n",
    ",'n02096585','n02097047','n02097130','n02097209'\n",
    ",'n02097298','n02097474','n02097658','n02098105'\n",
    ",'n02098286','n02098413','n02099267','n02099429'\n",
    ",'n02099601','n02099712','n02099849','n02100236'\n",
    ",'n02100583','n02100735','n02100877','n02101006'\n",
    ",'n02101388','n02101556','n02102040','n02102177'\n",
    ",'n02102318','n02102480','n02102973','n02104029'\n",
    ",'n02104365','n02105056','n02105162','n02105251'\n",
    ",'n02105412','n02105505','n02105641','n02105855'\n",
    ",'n02106030','n02106166','n02106382','n02106550'\n",
    ",'n02106662','n02107142','n02107312','n02107574'\n",
    ",'n02107683','n02107908','n02108000','n02108089'\n",
    ",'n02108422','n02108551','n02108915','n02109047'\n",
    ",'n02109525','n02109961','n02110063','n02110185'\n",
    ",'n02110341','n02110627','n02110806','n02110958'\n",
    ",'n02111129','n02111277','n02111500','n02111889'\n",
    ",'n02112018','n02112137','n02112350','n02112706'\n",
    ",'n02113023','n02113186','n02113624','n02113712'\n",
    ",'n02113799','n02113978']\n",
    "\n",
    "cats=['n02123045','n02123159','n02123394','n02123597','n02124075','n02125311','n02127052']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文件操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil \n",
    "import random\n",
    "from tqdm import *\n",
    "\n",
    "TRAIN_PATH = \"./train/\"\n",
    "TEST_PATH = \"./test/\"\n",
    "\n",
    "def checkDir(dir_path):\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "checkDir('train_link')\n",
    "checkDir('train_link/dog')\n",
    "checkDir('train_link/cat')\n",
    "checkDir('test_link')\n",
    "train_files = os.listdir(TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createLink():\n",
    "    train_files = os.listdir(TRAIN_PATH)\n",
    "    os.symlink('../test/', 'test_link/test')\n",
    "    for filename in tqdm(train_files):\n",
    "        if 'dog' in filename:\n",
    "            if os.path.exists('train_link/dog/' + filename):\n",
    "                continue\n",
    "            os.symlink('../../train/'+filename, 'train_link/dog/' + filename)\n",
    "        else:\n",
    "            if os.path.exists('train_link/cat/' + filename):\n",
    "                continue\n",
    "            os.symlink('../../train/' + filename, 'train_link/cat/' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def readOutliers():\n",
    "    with open('outliers.json', 'r') as json_file:\n",
    "        return json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeOutliers(key, files):\n",
    "    with open('outliers.json', 'r+') as json_file:\n",
    "            try:\n",
    "                outliers_dict = json.load(json_file)\n",
    "#                 print(outliers_dict)\n",
    "            except:\n",
    "                outliers_dict = {}\n",
    "            outliers_dict[key] = files\n",
    "            json_file.close()\n",
    "    with open('outliers.json','w') as json_file:\n",
    "        json_file.write(json.dumps(outliers_dict))\n",
    "        json_file.close()\n",
    "        \n",
    "# writeOutliers('key3',['1','2','3','555'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pylab as plb\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Dropout, Dense,Lambda\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.utils import shuffle\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.applications import Xception, InceptionResNetV2, DenseNet201\n",
    "import json as js\n",
    "from tqdm import *\n",
    "from keras.preprocessing.image import *\n",
    "import h5py\n",
    "from keras.applications import *\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "def get_train_test_data(height, doc_files = train_files):\n",
    "    labels = np.zeros(len(train_files))\n",
    "    train = np.zeros((len(train_files), height, height, 3), dtype=np.uint8)\n",
    "    test = np.zeros((12500, height, height, 3), dtype=np.uint8)\n",
    "    for idx, file in enumerate(tqdm(train_files)):\n",
    "        img = cv2.imread(TRAIN_PATH + file)\n",
    "        img = cv2.resize(img, (height, height))\n",
    "        train[idx] = img[:, :, ::-1]\n",
    "        if 'dog' in file:\n",
    "            labels[idx] = 1\n",
    "    for i in tqdm(range(12500)):\n",
    "        img = cv2.imread('./test/%s.jpg' % str(i + 1))\n",
    "        img = cv2.resize(img, (height, height))\n",
    "        test[i] = img[:, :, ::-1]\n",
    "    print('Training Data Size = %.2f GB' % (sys.getsizeof(train)/1024**3))\n",
    "    print('Testing Data Size = %.2f GB' % (sys.getsizeof(test)/1024**3))\n",
    "    return train, test,labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  数据可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "for file in train_files:\n",
    "    img = cv2.imread(TRAIN_PATH + file)\n",
    "    imgs.append(img.shape[0:2])\n",
    "#     break\n",
    "    \n",
    "imgs = np.array(imgs)\n",
    "x = imgs[:,0]\n",
    "y = imgs[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['random', '__version__', 'shuffle']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "plt.title('cat-width-height')\n",
    "plt.xlabel('Width')\n",
    "plt.ylabel('Height')\n",
    "plt.scatter(x, y, alpha = 0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理\n",
    "- 加载ImageNet猫狗的预测结果对比数据\n",
    "\n",
    "- 结合 Xception，InceptionResNetV2， DenseNet201 完成异常值检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['shuffle', 'random', '__version__']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "from PIL import Image\n",
    "subplots_adjust(left=0.0,bottom=0.0,top=0.1,right=0.1,hspace = 0)\n",
    "def showImge(files, doc= './train/', size = (12,12)):\n",
    "    fig = plt.figure(num= 'astronaut',figsize=size)\n",
    "    row = int(len(files) / 5 if len(files) % 5 == 0 else len(files) / 5 + 1)\n",
    "#     print(row)\n",
    "    for idx,file in enumerate(tqdm(files)):\n",
    "        img = Image.open(doc + file)    \n",
    "        plt.axis('on') # 关掉坐标轴为 off\n",
    "        plt.subplot(row,5,idx + 1)\n",
    "        plt.tight_layout()\n",
    "        plt.title(file)\n",
    "        fig.set_size_inches(20.5, 20.5 * row / 5,forward=True)\n",
    "        plt.imshow(img)\n",
    "    plt.show()\n",
    "# %pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_outliers(files,model,preprocess_input, target_size=(299, 299),top = 20):\n",
    "    outlier_files = []\n",
    "    np_cats = np.array(cats)\n",
    "    np_dogs = np.array(dogs)\n",
    "    for file in tqdm(files):\n",
    "        img = image.load_img(TRAIN_PATH + file, target_size=target_size)\n",
    "    #     print(\"file:\", file)\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        preds = model.predict(x)\n",
    "        pred = decode_predictions(preds, top= top)[0]\n",
    "        # 取交集\n",
    "        if 'dog' in file:\n",
    "            intersections = np.intersect1d(np.array(pred)[:,0],np_dogs)\n",
    "        else:\n",
    "            intersections = np.intersect1d(np.array(pred)[:,0],np_cats)\n",
    "\n",
    "        if len(intersections) == 0:\n",
    "            outlier_files.append(file)\n",
    "    return outlier_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 使用 Xception， InceptionResNetV2，InceptionV3，DenseNet201，分别取不同合理的top对数据检测异常值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xception \n",
    "from keras.applications.xception import preprocess_input as pre_x\n",
    "model = Xception(include_top=True,weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [03:19<00:00,  5.02it/s]\n"
     ]
    }
   ],
   "source": [
    "# 先取1000个数据，使用top= 10,20,30,40,50 对数据检查异常值\n",
    "outliers = process_outliers(train_files[:1000],model,pre_x,top=10)\n",
    "# showImge(outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Top = 10，误差还是很大的，对已经1000张已经检测出是异常值的猫狗图片，top = 20重新进行筛选检测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_20 = process_outliers(outliers,model,pre_x,top=20)\n",
    "# showImge(outliers_20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 发现top=20 还是有点误差，将\btop=30，40，50，60,70,80,检测范围提升至5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 30 检测大小提升至5000\n",
    "outliers_80 = process_outliers(outliers_70,model,pre_x,top=80)\n",
    "# showImge(outliers_80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TOP 调整至80后，发现异常值误差有明显的降低，使用top = 80 对所有的训练集做检测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_Vception = process_outliers(outliers_Vception,model,pre_x, top=80)\n",
    "# showImge(outliers_Vception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 将此模型的异常值保存为json文件\n",
    "writeOutliers('Xception',outliers_Vception)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 调整top提高精确度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:01<00:00, 24.03it/s]\n"
     ]
    }
   ],
   "source": [
    "outliers_Xception = readOutliers()['Xception']\n",
    "outliers_Xception = process_outliers(outliers_Xception, model,pre_x, top=110)\n",
    "# showImge(outliers_Xception)\n",
    "writeOutliers('Xception_110',outliers_Xception)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### InceptionResNetV2 检测异常值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_resnet_v2 import preprocess_input as pre_ResNetV2\n",
    "resNetV2Model = InceptionResNetV2(weights= 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_InceptionResNetV2 = process_outliers(outliers_InceptionResNetV2, resNetV2Model,pre_ResNetV2, top=80)\n",
    "writeOutliers('InceptionResNetV2',outliers_InceptionResNetV2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:03<00:00, 11.16it/s]\n"
     ]
    }
   ],
   "source": [
    "outliers_InceptionResNetV2 = readOutliers()['InceptionResNetV2']\n",
    "outliers_InceptionResNetV2 = process_outliers(outliers_InceptionResNetV2, resNetV2Model,pre_ResNetV2, top=120)\n",
    "# showImge(outliers_InceptionResNetV2)\n",
    "writeOutliers('InceptionResNetV2_120',outliers_InceptionResNetV2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用DenseNet201检测异常值调整top。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.densenet import preprocess_input as dense_pre\n",
    "dense_model = DenseNet201(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [32:12<00:00, 12.93it/s]\n"
     ]
    }
   ],
   "source": [
    "outliers_dense = process_outliers(train_files, dense_model, dense_pre, top=80,target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:03<00:00, 12.59it/s]\n"
     ]
    }
   ],
   "source": [
    "outliers_dense = readOutliers()['DenseNet201']\n",
    "outliers_dense = process_outliers(outliers_dense, dense_model, dense_pre, top=100,target_size=(224,224))\n",
    "writeOutliers('DenseNet201_100',outliers_dense)\n",
    "# showImge(outliers_dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 使用InceptionV3继续检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import preprocess_input as v3_pre\n",
    "from keras.applications import InceptionV3\n",
    "v3_model = InceptionV3(weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outliers_v3 = process_outliers(train_files, v3_model, v3_pre, top= 80, target_size = (224, 224))\n",
    "# showImge(outliers_v3)\n",
    "writeOutliers('InceptionV3', outliers_v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:02<00:00, 25.11it/s]\n"
     ]
    }
   ],
   "source": [
    "outliers_v3 = readOutliers()['InceptionV3']\n",
    "outliers_v3 = process_outliers(outliers_v3, v3_model, v3_pre, top= 190, target_size = (224, 224))\n",
    "# showImge(outliers_v3) \n",
    "writeOutliers('InceptionV3_190',outliers_v3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对以上四个模型的异常值取并集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def getAllOutliers():\n",
    "    out_keys = ['Xception_110', 'InceptionResNetV2_120', 'DenseNet201_120', 'InceptionV3_190']\n",
    "    outliers = []\n",
    "    outliersDict = readOutliers()\n",
    "    for k in out_keys:\n",
    "        outliers = list(set(outliers).union(set(readOutliers()[k])))\n",
    "    return outliers\n",
    "# len(getAllOutliers())\n",
    "# showImge(getAllOutliers())\n",
    "# writeOutliers('outliers_all',getAllOutliers())\n",
    "for file in getAllOutliers():\n",
    "    os.remove(TRAIN_PATH + file)\n",
    "    if 'dog' in file:\n",
    "        os.remove('train_link/dog/' + file)\n",
    "    else:\n",
    "        os.remove('train_link/cat/' + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24957/24957 [01:10<00:00, 356.32it/s]\n",
      "100%|██████████| 12500/12500 [00:35<00:00, 355.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Size = 6.23 GB\n",
      "Testing Data Size = 3.12 GB\n"
     ]
    }
   ],
   "source": [
    "train, test,labels = get_train_test_data(299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_gap(MODEL, target_size, lambda_func = None):\n",
    "    # Preprocess: Standardization\n",
    "    input_tensor = Input((target_size[1], target_size[0], 3))\n",
    "    x = input_tensor\n",
    "    if lambda_func:\n",
    "        x = Lambda(lambda_func)(x)\n",
    "    # Base Model: Extract feature vector of both train & test dataset\n",
    "    base_model = MODEL(input_tensor = x, weights='imagenet', include_top=False, pooling = 'avg')\n",
    "#     model = Model(base_model.input, GlobalAveragePooling2D()(base_model.output))\n",
    "    train_gap = base_model.predict(train, batch_size=128)\n",
    "    test_gap = base_model.predict(test, batch_size=128)\n",
    "    with h5py.File(\"gap_%s.h5\"%MODEL.__name__) as h:\n",
    "        h.create_dataset(\"train\", data=train_gap)\n",
    "        h.create_dataset(\"test\", data=test_gap)\n",
    "        h.create_dataset(\"label\", data=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_features_gap(InceptionV3, (299,299), inception_v3.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24957/24957 [00:59<00:00, 420.47it/s]\n",
      "100%|██████████| 12500/12500 [00:29<00:00, 421.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Size = 3.50 GB\n",
      "Testing Data Size = 1.75 GB\n"
     ]
    }
   ],
   "source": [
    "train, test,labels = get_train_test_data(224)\n",
    "get_features_gap(ResNet50, (224,224), resnet50.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24957/24957 [01:09<00:00, 356.68it/s]\n",
      "100%|██████████| 12500/12500 [00:35<00:00, 355.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Size = 6.23 GB\n",
      "Testing Data Size = 3.12 GB\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.7/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "219062272/219055592 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "train, test,labels = get_train_test_data(299)\n",
    "get_features_gap(InceptionResNetV2, (299,299), inception_resnet_v2.preprocess_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "np.random.seed(2017)\n",
    "x_train = []\n",
    "x_test = []\n",
    "for file in ['gap_InceptionV3', 'gap_InceptionResNetV2', 'gap_ResNet50']:\n",
    "    with h5py.File(file + '.h5', 'r') as h:\n",
    "        x_train.append(np.array(h['train']))\n",
    "        x_test.append(np.array(h['test']))\n",
    "        y_train = np.array(h['label'])\n",
    "x_train = np.concatenate(x_train, axis=1)\n",
    "x_test = np.concatenate(x_test, axis=1)\n",
    "x_train, y_train = shuffle(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 5632)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 5632)              0         \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           (None, 1)                 5633      \n",
      "=================================================================\n",
      "Total params: 5,633\n",
      "Trainable params: 5,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_gap, X_val_gap, y_train_gap, y_val_gap = train_test_split(x_train, y_train, shuffle=True, test_size=0.2,\\\n",
    "                                                                  random_state=42)\n",
    "# Input Shape: (Batch Size, Feature Vector length)\n",
    "x = Input(shape=(X_train_gap.shape[1],))\n",
    "y = Dropout(0.2)(x)\n",
    "y = Dense(1, activation='sigmoid', kernel_initializer='he_normal', name='classifier')(y)\n",
    "model_gap = Model(inputs=x, outputs=y, name='GAP')\n",
    "model_gap.compile(loss='binary_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "print(model_gap.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19965 samples, validate on 4992 samples\n",
      "Epoch 1/10\n",
      "19965/19965 [==============================] - 4s 212us/step - loss: 0.0229 - acc: 0.9934 - val_loss: 0.0112 - val_acc: 0.9972\n",
      "Epoch 2/10\n",
      "19965/19965 [==============================] - 4s 209us/step - loss: 0.0135 - acc: 0.9957 - val_loss: 0.0133 - val_acc: 0.9966\n",
      "Epoch 3/10\n",
      "19965/19965 [==============================] - 4s 212us/step - loss: 0.0119 - acc: 0.9965 - val_loss: 0.0125 - val_acc: 0.9970\n",
      "Epoch 4/10\n",
      "19965/19965 [==============================] - 4s 213us/step - loss: 0.0107 - acc: 0.9967 - val_loss: 0.0113 - val_acc: 0.9976\n",
      "Epoch 5/10\n",
      "19965/19965 [==============================] - 4s 208us/step - loss: 0.0095 - acc: 0.9974 - val_loss: 0.0123 - val_acc: 0.9974\n",
      "Epoch 6/10\n",
      "19965/19965 [==============================] - 4s 214us/step - loss: 0.0091 - acc: 0.9976 - val_loss: 0.0124 - val_acc: 0.9972\n",
      "Epoch 7/10\n",
      "19965/19965 [==============================] - 4s 215us/step - loss: 0.0087 - acc: 0.9973 - val_loss: 0.0127 - val_acc: 0.9972\n",
      "Epoch 8/10\n",
      "19965/19965 [==============================] - 4s 217us/step - loss: 0.0074 - acc: 0.9981 - val_loss: 0.0126 - val_acc: 0.9974\n",
      "Epoch 9/10\n",
      "19965/19965 [==============================] - 4s 223us/step - loss: 0.0074 - acc: 0.9979 - val_loss: 0.0136 - val_acc: 0.9972\n",
      "Epoch 10/10\n",
      "19965/19965 [==============================] - 4s 208us/step - loss: 0.0065 - acc: 0.9982 - val_loss: 0.0134 - val_acc: 0.9976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8e0186b240>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "# Prepare Callbacks for Model Checkpoint, Early Stopping and Tensorboard.\n",
    "log_name = '/gap_merge.h5'\n",
    "log_dir = datetime.now().strftime('finetune_model_%Y%m%d_%H%M')\n",
    "if not os.path.exists(log_dir):\n",
    "    os.mkdir(log_dir)\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "mc = ModelCheckpoint(log_dir + log_name, monitor='val_loss', save_best_only=True)\n",
    "tb = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "model_gap.fit(x=X_train_gap, y = y_train_gap, batch_size=16, epochs=10, validation_data=(X_val_gap, y_val_gap), \\\n",
    "              callbacks=[es, mc, tb])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------------------------------------------------------------------------------------------------------\n",
    "### Write in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 1s 47us/step\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label\n",
       "0   1    0.5\n",
       "1   2    0.5\n",
       "2   3    0.5\n",
       "3   4    0.5\n",
       "4   5    0.5\n",
       "5   6    0.5\n",
       "6   7    0.5\n",
       "7   8    0.5\n",
       "8   9    0.5\n",
       "9  10    0.5"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##predict\n",
    "y_pred = model_gap.predict(x_test, verbose=1)\n",
    "y_pred = y_pred.clip(min=0.003, max=0.997)\n",
    "\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import *\n",
    "\n",
    "df = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "gen = ImageDataGenerator()\n",
    "test_generator = gen.flow_from_directory(\"test_link\", (224, 224), shuffle=False, \n",
    "                                         batch_size=16, class_mode=None)\n",
    "\n",
    "for i, fname in enumerate(test_generator.filenames):\n",
    "    index = int(fname[fname.rfind('/')+1:fname.rfind('.')])\n",
    "    df.set_value(index-1, 'label', y_pred[i])\n",
    "\n",
    "df.to_csv('pred.csv', index=None)\n",
    "df.head(10)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Environment (conda_anaconda3)",
   "language": "python",
   "name": "conda_anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
